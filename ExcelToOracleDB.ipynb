{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install cx_Oracle --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OracleDB CX Oracle Python library \n",
    "# https://developer.oracle.com/dsl/prez-python-queries.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cx_Oracle\n",
    "from sqlalchemy import types, create_engine\n",
    "from types import *\n",
    "from pprint import pprint\n",
    "import cx_Oracle\n",
    "import sqlalchemy as sa\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All static vars go here\n",
    "dbType = \"OracleDB\"\n",
    "\n",
    "dbUser = \"achem_drm\"\n",
    "dbPassword = \"p1rosalma\"\n",
    "dbHost = \"dalbcedd1.na.xom.com\"\n",
    "dbName = \"bced\"\n",
    "dbPort = \"55009\"\n",
    "\n",
    "#OracleDB Connection strings\n",
    "oracleConnStr = 'oracle+cx_oracle://'+ dbUser + ':' + dbPassword + \"@\" + dbHost +':'+ dbPort +'/' + dbName\n",
    "oracleDatabaseEngine = sa.create_engine(oracleConnStr)\n",
    "oracleDbConnection = oracleDatabaseEngine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare location of Config file and root directory for data here\n",
    "#Assumes that these directories will be accessible to the code\n",
    "configFile = \"workspace/de/drm-de/excelUploadAutomation/config.xlsx\"\n",
    "configSheet = \"config\"\n",
    "dataDirectory = \"workspace/de/drm-de/excelUploadAutomation/sampleData/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the config file here\n",
    "configDf = pd.read_excel(open(configFile, 'rb'), sheet_name=configSheet, encoding='latin-1')\n",
    "configDf = configDf.dropna(how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runOracleQuery(sqlQuery):\n",
    "    ##################################################################################\n",
    "    # Helper function\n",
    "    # Function to run Oracle Query and print output\n",
    "    # Takes input SQL Query and database congigurations\n",
    "    # DB configuration is expected to be pre-declared in scope to the function call\n",
    "    ##################################################################################\n",
    "    try:\n",
    "        oracleTns = cx_Oracle.makedsn(dbHost, dbPort, dbName)\n",
    "        dbConnection = cx_Oracle.connect(dbUser, dbPassword, oracleTns)\n",
    "        \n",
    "        cursor = dbConnection.cursor()\n",
    "        cursor.execute(sqlQuery)\n",
    "        dbConnection.commit()\n",
    "\n",
    "        try:\n",
    "            data = cursor.fetchall()\n",
    "            pprint(cursor.description)\n",
    "            pprint(data)\n",
    "        except:\n",
    "            print(\"DEBUG: Not a data query, no data to print\")\n",
    "\n",
    "        cursor.close()\n",
    "        dbConnection.close()\n",
    "        print(\"DEBUG: Query executed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong executing the query\")\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTableAsDf(dbConnection, tableName):\n",
    "    ##################################################################################\n",
    "    # Helper function\n",
    "    # Function to run Oracle Query and print output\n",
    "    # Takes input SQL Query and database congigurations\n",
    "    # No need to pass DB configuration if database variables are already declared where the function is called\n",
    "    ##################################################################################\n",
    "    query = \"SELECT * FROM \" + tableName\n",
    "    try:\n",
    "        readDf = pd.read_sql(query, con=dbConnection)\n",
    "        return readDf\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while fetching the table\")\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncateTable(tableName, taskId):\n",
    "    ##################################################################################\n",
    "    # Helper function\n",
    "    # Function to truncate a table from OracleDB\n",
    "    # Takes input table name\n",
    "    ##################################################################################\n",
    "    try:\n",
    "        sqlQuery = \"TRUNCATE TABLE \" + tableName\n",
    "        runOracleQuery(sqlQuery)\n",
    "        print(\"DEBUG: Truncated table \" + tableName)\n",
    "        return \"Success\"\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while truncating the table \" + tableName + \" in task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "        return \"Failure\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameColums(df, columnsRenamed, taskId):\n",
    "    ##################################################################################\n",
    "    # Function to rename column names for a dataframe\n",
    "    # Expects new names for EVERY column in the dataframe\n",
    "\n",
    "    # columnsRenamed -> Comma seperated string containing new names for columns\n",
    "    # taskId -> Task ID is passed to the function for debugging purpose\n",
    "    # df -> Pandas dataframe to which the column rename function is applied \n",
    "    \n",
    "    #Alternatively, to rename selective columns, enter oldName : newName key value pairs\n",
    "    ##################################################################################\n",
    "\n",
    "    if columnsRenamed.lower() in [\"\", None, \"nan\"]:\n",
    "        return df\n",
    "\n",
    "    columnsRenamed = columnsRenamed.split(',') \n",
    "    \n",
    "    if len(columnsRenamed) == len(df.columns):\n",
    "        columnsToRename = {}\n",
    "        try:\n",
    "            for i in range(len(columnsRenamed)):\n",
    "                columnsToRename[df.columns.values[i].strip()] = columnsRenamed[i].strip()\n",
    "            df = df.rename(columns=columnsToRename)\n",
    "            return df\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: Something went wrong while renaming columns for task id \" + taskId)\n",
    "            print(\"ERROR: \" + str(type(e).__name__))\n",
    "            print(\"ERROR: \" + str(e))\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        renameDict = {}\n",
    "        for i in columnsRenamed:\n",
    "            i = i.strip()\n",
    "            i = i.split(':')\n",
    "            renameDict[i[0].strip()] = i[1].strip()\n",
    "        try:\n",
    "            df.rename(columns = renameDict, inplace = True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(\"ERROR: Something went wrong while renaming columns for task id \" + taskId)\n",
    "            print(\"ERROR: \" + str(type(e).__name__))\n",
    "            print(\"ERROR: \" + str(e))\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changeDataType(df, changeDataTypeConditions, taskId):\n",
    "    ##################################################################################\n",
    "    # Function to change data types for columns in a dataframe\n",
    "\n",
    "    # changeDataTypeConditions -> Comma seperated key value pairs of format COLUMN-NAME: DATA-TYPE\n",
    "    # taskId -> Task ID is passed to the function for debugging purpose\n",
    "    # df -> Pandas dataframe to which the column data type conversion is applied\n",
    "    \n",
    "    # Supported Data types are:\n",
    "    # object, int64, float64, datetime64, bool\n",
    "    ##################################################################################\n",
    "    \n",
    "    if changeDataTypeConditions.lower() in [\"\", None, \"nan\"]:\n",
    "        return df \n",
    "    \n",
    "    changeDataTypeConditions = changeDataTypeConditions.split(',')\n",
    "    changeDataTypeDictionary = {}\n",
    "    \n",
    "    try:\n",
    "        for i in changeDataTypeConditions:\n",
    "            i = i.strip()\n",
    "            i = i.split(':')\n",
    "            changeDataTypeDictionary[i[0].strip()] = i[1].strip()\n",
    "            df = df.astype(changeDataTypeDictionary)\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while changing data type for task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "        print(\"DEBUG: Continuing without changing column type\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterData(df, filterConditionsRaw, taskId):\n",
    "    ##################################################################################\n",
    "    # Function to filter rows from data frame\n",
    "\n",
    "    # filterDataConditions -> Expression for the filter to be applied\n",
    "    # taskId -> Task ID is passed to the function for debugging purpose\n",
    "    # df -> Pandas dataframe to which the filter is applied\n",
    "    ##################################################################################\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        filterDataConditions = filterConditionsRaw.split('||')\n",
    "        filteredDf = pd.DataFrame()\n",
    "\n",
    "        for condition in filterDataConditions:\n",
    "            condition = condition.strip()\n",
    "            condition = condition.split('&&')\n",
    "            outDf = df\n",
    "\n",
    "            for individualCondition in condition:\n",
    "                individualCondition = individualCondition.strip()\n",
    "\n",
    "                if '>' in individualCondition:\n",
    "                    data = individualCondition.split('>')\n",
    "                    colName = data[0].strip()\n",
    "                    filterValue = data[1].strip()\n",
    "                    if colName[0] == '\"' and colName[-1] == '\"':\n",
    "                        colName = colName[1:-1]\n",
    "                    if filterValue[0] == '\"' and filterValue[-1] == '\"':\n",
    "                        filterValue = float(filterValue)\n",
    "                    outDf = outDf[outDf[colName] > filterValue]\n",
    "\n",
    "\n",
    "                elif '<'in individualCondition:\n",
    "                    data = individualCondition.split('<')\n",
    "                    colName = data[0].strip()\n",
    "                    filterValue = data[1].strip()\n",
    "                    if colName[0] == '\"' and colName[-1] == '\"':\n",
    "                        colName = colName[1:-1]\n",
    "                    if filterValue[0] == '\"' and filterValue[-1] == '\"':\n",
    "                        filterValue = (filterValue[1:-1])\n",
    "                    else:\n",
    "                        filterValue = float(filterValue)\n",
    "                    outDf = outDf[outDf[colName] < filterValue]\n",
    "\n",
    "                elif '>=' in individualCondition:\n",
    "                    data = individualCondition.split('>=')\n",
    "                    colName = data[0].strip()\n",
    "                    filterValue = data[1].strip()\n",
    "                    if colName[0] =='\"' and colName[-1] == '\"':\n",
    "                        colName = colName[1:-1]\n",
    "                    if filterValue[0] == '\"' and filterValue[-1] == '\"':\n",
    "                        filterValue = (filterValue[1:-1])\n",
    "                    else:\n",
    "                        filterValue = float(filterValue)\n",
    "                    outDf = outDf[outDf[colName] >= filterValue]\n",
    "\n",
    "                elif '<='in individualCondition:\n",
    "                    data = individualCondition.split('<=')\n",
    "                    colName = data[0].strip()\n",
    "                    filterValue = data[1].strip()\n",
    "                    if colName[0] == '\"' and colName[-1] == '\"':\n",
    "                        colName = colName[1:-1]\n",
    "                    if filterValue[0] == '\"' and filterValue[-1] == '\"':\n",
    "                        filterValue = (filterValue[1:-1])\n",
    "                    else:\n",
    "                        filterValue = float(filterValue)\n",
    "                    outDf = outDf[outDf[colName] <= filterValue]\n",
    "\n",
    "                elif '==' in individualCondition:\n",
    "                    data = individualCondition.split('==')\n",
    "                    colName = data[0].strip()\n",
    "                    filterValue = data[1].strip()\n",
    "                    if colName[0] == '\"' and colName[-1] == '\"':\n",
    "                        colName = colName[1:-1]\n",
    "                    if filterValue[0] == '\"' and filterValue[-1] == '\"':\n",
    "                        filterValue = (filterValue[1:-1])\n",
    "                    else:\n",
    "                        filterValue = float(filterValue)\n",
    "                    outDf = outDf[outDf[colName] == filterValue]\n",
    "\n",
    "                elif '!='in individualCondition:\n",
    "                    data = individualCondition.split('!=')\n",
    "                    colName = data[0].strip()\n",
    "                    filterValue = data[1].strip()\n",
    "                    if colName[0] == '\"' and colName[-1] == '\"':\n",
    "                        colName = colName[1:-1]\n",
    "                    if filterValue[0] == '\"' and filterValue[-1] == '\"':\n",
    "                        filterValue = (filterValue[1:-1])\n",
    "                    else:\n",
    "                        filterValue = float(filterValue)\n",
    "                    outDf = outDf[outDf[colName] != filterValue]\n",
    "\n",
    "            filteredDf = pd.concat([filteredDf,outDf],ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "        return filteredDf\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while applying filter conditions for task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertAdditionalColumns(df, insertColumns, taskId):\n",
    "    ##################################################################################\n",
    "    # Function to insert specific new columns into a dataframe\n",
    "\n",
    "    # insertColumns -> Comma seperated list of new columns to be inserted\n",
    "    # taskId -> Task ID is passed to the function for debugging purpose\n",
    "    # df -> Pandas dataframe into which the new columns are inserted\n",
    "    \n",
    "    # Supported columns:\n",
    "    # UPLOAD_TIME\n",
    "    ##################################################################################\n",
    "    \n",
    "    if insertColumns.lower() in [\"\", None, \"nan\"]:\n",
    "        return df \n",
    "\n",
    "    insertColumns = insertColumns.split(',')\n",
    "    \n",
    "    for i in insertColumns:\n",
    "        if i.strip().lower() == \"upload_time\":\n",
    "            now = datetime.now()\n",
    "            current_time = now.strftime(\"%H:%M:%S\")\n",
    "            df['UPLOAD_TIME'] = (current_time)\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceData(df, replaceDataConditions, taskId):\n",
    "    ##################################################################################\n",
    "    # Function to replace values in a dataframe\n",
    "\n",
    "    # replaceDataConditions -> Key Value pair where key is the column name, and value is a doctionary with data replacement conditions\n",
    "    # taskId -> Task ID is passed to the function for debugging purpose\n",
    "    # df -> Pandas dataframe to which the data replacements are applied\n",
    "    ##################################################################################\n",
    "    \n",
    "    if replaceDataConditions.lower() in [\"\", None, \"nan\"]:\n",
    "        return df \n",
    "    \n",
    "    replaceDataConditions = replaceDataConditions.split(',')\n",
    "    \n",
    "    try:\n",
    "        for i in replaceDataConditions:\n",
    "            i = i.strip()\n",
    "            i = i.split(':',1)\n",
    "            col_name=i[0]\n",
    "            conditions=i[1].replace('{','').replace('}',\"\").split('|')\n",
    "            col_type=str(df[col_name].dtype)\n",
    "            for condition in conditions:\n",
    "                condition = condition.strip()\n",
    "                old,new = condition.split(\":\")\n",
    "                if old.lower() in ['nan','n.a.','n.a','na','']:\n",
    "                    if 'float' in col_type:\n",
    "                        df[col_name]=df[col_name].fillna(float(new))\n",
    "                    elif 'int' in col_type:\n",
    "                        df[col_name]=df[col_name].fillna(int(new))\n",
    "                    elif 'obj' in col_type:\n",
    "                        df[col_name]=df[col_name].replace(old,new)\n",
    "                else:\n",
    "                    if 'float' in col_type:\n",
    "                        df[col_name]=df[col_name].replace(float(old),float(new))\n",
    "                    elif 'int' in col_type:\n",
    "                        df[col_name]=df[col_name].replace(int(old),int(new))\n",
    "                    elif 'obj' in col_type:\n",
    "                        df[col_name]=df[col_name].replace(old,new)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while replacing data for task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDateTime(df, formatDateTimeConditions, taskId):\n",
    "    ##################################################################################\n",
    "    # Function to format dates in a dataframe\n",
    "\n",
    "    # formatDateTimeConditions -> Comma seperated key value pair where key is column name and value is new date format\n",
    "    # taskId -> Task ID is passed to the function for debugging purpose\n",
    "    # df -> Pandas dataframe to which the date transformations are applied\n",
    "    ##################################################################################\n",
    "    \n",
    "    if formatDateTimeConditions.lower() in [\"\", None, \"nan\"]:\n",
    "        return df \n",
    "    \n",
    "    try:\n",
    "        formatDateTimeConditions=formatDateTimeConditions.split(',')\n",
    "        for i in formatDateTimeConditions:\n",
    "            i = i.strip()\n",
    "            col,new_format = i.split(':',1)\n",
    "            df[col]=pd.to_datetime(df[col]).dt.strftime(new_format)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while formating datetime for task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfInsertToTable(df, tableName, taskId, startRow = 0):\n",
    "                \n",
    "    startRow = int(startRow)\n",
    "\n",
    "    oracleTns = cx_Oracle.makedsn(dbHost, dbPort, dbName)\n",
    "    dbConnection = cx_Oracle.connect(dbUser, dbPassword, oracleTns, encoding = \"UTF-8\", nencoding = \"UTF-8\")\n",
    "    \n",
    "    cursor = dbConnection.cursor()\n",
    "    cursor1 = dbConnection.cursor()\n",
    "    \n",
    "    cursor1.execute(\"SELECT * FROM \" + tableName + \" fetch first 3 rows only\")\n",
    "    \n",
    "    dbConnection.commit()\n",
    "    rowsTemp = cursor1.fetchall()\n",
    "    cursor.bindarraysize = len(rowsTemp)\n",
    "    db_types = (d[1] for d in cursor1.description)\n",
    "    cursor.setinputsizes(*db_types)\n",
    "    cursor1.close()\n",
    "            \n",
    "    trackerIndex = 0\n",
    "    for index, row in df[startRow:].iterrows():\n",
    "        try:\n",
    "            trackerIndex = index\n",
    "\n",
    "            rowData = \"\"\n",
    "            counter = 1\n",
    "            for i in row:\n",
    "                rowData = rowData + \" :\" + str(counter) + \" ,\"\n",
    "                counter += 1\n",
    "            rowData = rowData[:-2]\n",
    "\n",
    "            columnNamesString = []\n",
    "            for i in df.columns.values:\n",
    "                temp = '\"' + i + '\"'\n",
    "                columnNamesString.append(temp)\n",
    "            columns = (',').join(columnNamesString)\n",
    "\n",
    "            sqlQuery = \"INSERT INTO \" + tableName + \" (\" + columns +  \") VALUES\" + \"(\" + rowData + \")\"\n",
    "            \n",
    "            map(lambda x: x.encode('utf-8'), row)\n",
    "            \n",
    "            cursor.execute(sqlQuery, row)\n",
    "            dbConnection.commit()\n",
    "            \n",
    "            if index % 1000 == 0:\n",
    "                print(\"DEBUG: Writing row \" + str(index) + \" for task id \" + str(taskId))\n",
    "        \n",
    "        except Exception as e:\n",
    "            #Failed at row startRow\n",
    "            print(row)\n",
    "            print(\"ERROR: Something went wrong while writing to table \" + tableName + \" for task id \" + taskId)\n",
    "            print(\"DEBUG: Failed at row \" + str(trackerIndex))\n",
    "            print(\"ERROR: \" + str(type(e).__name__))\n",
    "            print(\"ERROR: \" + str(e))\n",
    "            cursor.close()\n",
    "            dbConnection.close()\n",
    "            return \"Failure\"\n",
    "        \n",
    "    print(\"DEBUG: Insert successful\")\n",
    "    cursor.close()\n",
    "    dbConnection.close()\n",
    "    return \"Success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfUpdateToTable(df, tableName, taskId, upsertKey, startRow = 0):\n",
    "    startRow = int(startRow)\n",
    "    \n",
    "    upsertKeys = upsertKey.strip().split(',')\n",
    "    map(lambda x: x.strip(), upsertKeys)\n",
    "    \n",
    "    oracleTns = cx_Oracle.makedsn(dbHost, dbPort, dbName)\n",
    "    dbConnection = cx_Oracle.connect(dbUser, dbPassword, oracleTns, encoding = \"UTF-8\", nencoding = \"UTF-8\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    cursor = dbConnection.cursor()\n",
    "    ############################Delete query creation#########################\n",
    "    try:\n",
    "        tempDf = df[upsertKeys].drop_duplicates() \n",
    "        \n",
    "        \n",
    "        for index, row in tempDf.iterrows():\n",
    "            whereClause = \"\"\n",
    "            counter = 1\n",
    "\n",
    "            for i in upsertKeys:\n",
    "                whereClause = whereClause +  '\"' + i.strip() + '\" = :' + str(counter) + ' AND '\n",
    "                counter += 1\n",
    "            \n",
    "            whereClause = whereClause[:-4]\n",
    "            sqlQueryDelete = \"DELETE FROM \" + str(tableName) + \" WHERE \" + whereClause\n",
    "            map(lambda x: x.encode('utf-8'), row)\n",
    "            cursor.execute(sqlQueryDelete, row)\n",
    "            dbConnection.commit()\n",
    "            \n",
    "        print(\"DEBUG: Deleted the existing values, Now starting insert\")\n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong while deleting for upsert keys in table \" + tableName + \" for task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))\n",
    "    cursor.close()\n",
    "    ############################Delete query creation#########################\n",
    "    \n",
    "    \n",
    "    ############################Insert query creation#########################\n",
    "    \n",
    "    cursor1 = dbConnection.cursor()\n",
    "    cursor = dbConnection.cursor()\n",
    "\n",
    "    cursor1.execute(\"SELECT * FROM \" + tableName + \" fetch first 3 rows only\")\n",
    "    dbConnection.commit()\n",
    "    rowsTemp = cursor1.fetchall()\n",
    "    cursor.bindarraysize = len(rowsTemp)\n",
    "    db_types = (d[1] for d in cursor1.description)\n",
    "    cursor.setinputsizes(*db_types)\n",
    "    cursor1.close()\n",
    "            \n",
    "    trackerIndex = 0\n",
    "    for index, row in df[startRow:].iterrows():\n",
    "        try:\n",
    "            trackerIndex = index\n",
    "            \n",
    "            rowData = \"\"\n",
    "            counter = 1\n",
    "            for i in row:\n",
    "                rowData = rowData + \" :\" + str(counter) + \" ,\"\n",
    "                counter += 1\n",
    "            rowData = rowData[:-2]\n",
    "            columnNamesString = []\n",
    "            for i in df.columns.values:\n",
    "                temp = '\"' + i + '\"'\n",
    "                columnNamesString.append(temp)\n",
    "            columns = (',').join(columnNamesString)\n",
    "            sqlQueryInsert = \"INSERT INTO \" + tableName + \" (\" + columns +  \") VALUES\" + \"(\" + rowData + \")\"\n",
    "            map(lambda x: x.encode('utf-8'), row)\n",
    "            cursor.execute(sqlQueryInsert, row)\n",
    "            dbConnection.commit()\n",
    "            \n",
    "            if index % 1000 == 0:\n",
    "                print(\"DEBUG: Writing row \" + str(index) + \" for task id \" + str(taskId))\n",
    "            \n",
    "        except Exception as e:\n",
    "            #Failed at row startRow\n",
    "            print(\"ERROR: Something went wrong while writing to table \" + tableName + \" for task id \" + taskId)\n",
    "            print(\"DEBUG: Failed at row \" + str(trackerIndex))\n",
    "            print(\"ERROR: \" + str(type(e).__name__))\n",
    "            print(\"ERROR: \" + str(e))\n",
    "            cursor1.close()\n",
    "            cursor.close()\n",
    "            dbConnection.close()\n",
    "            return \"Failure\"\n",
    "    ############################Insert query creation#########################\n",
    "        \n",
    "    cursor.close()  \n",
    "    dbConnection.close() \n",
    "    print(\"DEBUG: Update successful\")\n",
    "    return \"Success\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeDfToDb(df, tableName, upsertKey, truncateBool, resumeFromRow, taskId):\n",
    "    \n",
    "    if dbType == \"OracleDB\":\n",
    "\n",
    "        if resumeFromRow not in [\"\", \"0\", 0, \"nan\", None]:\n",
    "            #If resuming, then no need to truncate\n",
    "            \n",
    "            if upsertKey in [\"\", \"nan\",None]:\n",
    "                #Not upserting, simply insert data\n",
    "                dfInsertToTable(df, tableName, taskId, resumeFromRow)\n",
    "            else:\n",
    "                #Upserting / Updating the data for a particular key\n",
    "                dfUpdateToTable(df, tableName, taskId, upsertKey, resumeFromRow)\n",
    "                \n",
    "        else:\n",
    "            if truncateBool in [\"1\", 1, True, \"True\"]:\n",
    "                deleteStatus = truncateTable(tableName, taskId)\n",
    "                if deleteStatus == \"Failure\":\n",
    "                    return \"Failure\"\n",
    "            \n",
    "            if upsertKey in [\"\", \"nan\",None]:\n",
    "                #Not upserting, simply insert data\n",
    "                dfInsertToTable(df, tableName, taskId)\n",
    "                \n",
    "            else:\n",
    "                #Upserting / Updating the data for a particular key\n",
    "                dfUpdateToTable(df, tableName, taskId,  upsertKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEBUG: Running task 17 for table DP_ZEMA_IHS_DAILY_BKUP\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must specify a fill 'value' or 'method'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-671295b33a6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mdataDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mdataDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mdataDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m#Replace data for selected columns based on input conditions of format: col5:{25:26}, col6:{123:124}, col7:{nan:0}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/anaconda50_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   4032\u001b[0m                      \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4033\u001b[0m                                   \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4034\u001b[0;31m                                   downcast=downcast, **kwargs)\n\u001b[0m\u001b[1;32m   4035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4036\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/anaconda50_py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   6042\u001b[0m         \"\"\"\n\u001b[1;32m   6043\u001b[0m         \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inplace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6044\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_fillna_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6046\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/anaconda50_py36/lib/python3.6/site-packages/pandas/util/_validators.py\u001b[0m in \u001b[0;36mvalidate_fillna_kwargs\u001b[0;34m(value, method, validate_scalar_dict_value)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must specify a fill 'value' or 'method'.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must specify a fill 'value' or 'method'."
     ]
    }
   ],
   "source": [
    "for index, row in configDf.iterrows():\n",
    "    #Iterate the config for individual data transformations\n",
    "    \n",
    "    #Record the start time for debuging purpose\n",
    "    start_time = time.time()\n",
    "\n",
    "    ####################################################################################################\n",
    "    #Reading configurations data here\n",
    "    \n",
    "    #Adding '1' to ignore column will skip the test\n",
    "    if row['ignore'] in ['1', 1]:\n",
    "        continue\n",
    "    \n",
    "    taskId = row['id']\n",
    "    if taskId == \"\":\n",
    "        continue\n",
    "    \n",
    "        \n",
    "    dataFile = dataDirectory + str(row['fileName']).strip()\n",
    "    sheetName = str(row['sheetName']).strip()\n",
    "    \n",
    "    skipFromRow = row['skipFromRow']\n",
    "    skipTillRow = row['skipTillRow']\n",
    "    headerRow = row['headerRow']\n",
    "    \n",
    "    columns = str(row['columns']).strip()\n",
    "    \n",
    "    columnsRenamed = str(row['columnsRenamed']).strip()\n",
    "    filterDataConditions = str(row[\"filterDataCondition\"]).strip()\n",
    "    replaceDataConditions = str(row[\"replaceDataCondition\"]).strip()\n",
    "    changeDataTypeConditions = str(row[\"changeDataTypeCondition\"]).strip()\n",
    "    formatDateTimeConditions = str(row[\"formatDateTimeCondition\"]).strip()\n",
    "\n",
    "    tableName = str(row['tableName']).strip()\n",
    "    \n",
    "    truncateBool = str(row['truncateBool']).strip()\n",
    "    upsertKey = str(row['upsertKey']).strip()\n",
    "        \n",
    "    #Insert Additional columns\n",
    "    additionalCols = str(row['additionalCols']).strip()\n",
    "    ####################################################################################################\n",
    "     \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    ####################################################################################################\n",
    "    #Making sanity checks on basic data\n",
    "    \n",
    "    print()\n",
    "    print(\"DEBUG: Running task \" + str(taskId) + \" for table \" + str(tableName))\n",
    "    \n",
    "    if type(taskId)!=int:\n",
    "        print(\"ERROR: 'Task id' should be integer. Incorrect format for task id \" + taskId)\n",
    "        continue\n",
    "    else:\n",
    "        taskId = str(taskId)\n",
    "       \n",
    "    try:\n",
    "        headerRow = int(row['headerRow'])\n",
    "    except Exception as e:\n",
    "        headerRow = 1\n",
    "        \n",
    "    try:\n",
    "        skipFromRow = int(row['skipFromRow']) - 1\n",
    "    except Exception as e:\n",
    "        skipFromRow = 0\n",
    "        \n",
    "    try:\n",
    "        skipTillRow = int(row['skipTillRow']) - 1\n",
    "    except Exception as e:\n",
    "        skipTillRow = 0\n",
    "        \n",
    "    if truncateBool not in [\"\", \"0\", \"1\", \"nan\"]:\n",
    "        print(\"ERROR: Invalid truncate Bool, please check the configuration for task id \" + taskId)\n",
    "        continue\n",
    "                \n",
    "    if columns in [\"\", None, \"nan\"]:\n",
    "        columns = None\n",
    "    \n",
    "    if str(row['resumeFromRow']) in [\"\", \"nan\", 0, None, \"0\", \"Nan\", \"NaN\"]:\n",
    "        resumeFromRow = 0\n",
    "    else:\n",
    "        #Restart processing from row (Failure handling)\n",
    "        resumeFromRow = int(row['resumeFromRow'])\n",
    "        \n",
    "    ####################################################################################################\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Read the excel file to be uploaded\n",
    "    dataDf = pd.read_excel(open(dataFile, 'rb'), sheet_name=sheetName ,  usecols=columns, skiprows=range(skipFromRow, skipTillRow))\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #Applying data transformations\n",
    "    \n",
    "    \n",
    "    #Rename columns using input list of format: old1:new1, old2:new2......\n",
    "    dataDf = renameColums(dataDf, columnsRenamed, taskId)\n",
    "    if (dataDf.empty == True):\n",
    "        continue\n",
    "    \n",
    "    #Apply filters on excel data using input conditions of format: col1<10 & col2>100 | col3=100 | col4!=19\n",
    "    dataDf = filterData(dataDf, filterDataConditions, taskId)\n",
    "    if (dataDf.empty == True):\n",
    "        continue\n",
    "        \n",
    "        \n",
    "    dataDf = dataDf.replace('#', np.nan)\n",
    "    dataDf = dataDf.replace(np.nan, '', regex=True)\n",
    "    dataDf = dataDf.fillna()\n",
    "    \n",
    "    #Replace data for selected columns based on input conditions of format: col5:{25:26}, col6:{123:124}, col7:{nan:0}    \n",
    "    dataDf = replaceData(dataDf, replaceDataConditions, taskId)\n",
    "    if (dataDf.empty == True):\n",
    "        continue    \n",
    "    \n",
    "    #Format DateTime columns based on input conditions of format: col8:%Y-%b-%d, col9:%Y-%b-%d %H:%M:%S %p\n",
    "    dataDf = formatDateTime(dataDf, formatDateTimeConditions, taskId)\n",
    "    if (dataDf.empty == True):\n",
    "        continue \n",
    "        \n",
    "        \n",
    "    #Insert additional columns \n",
    "    dataDf = insertAdditionalColumns(dataDf, additionalCols, taskId)\n",
    "    if (dataDf.empty == True):\n",
    "        continue \n",
    "        \n",
    "    \n",
    "    #Change data type for selected columns based on input conditions of format: col5:float, col6:int, col7:str\n",
    "    dataDf = changeDataType(dataDf, changeDataTypeConditions, taskId)\n",
    "    if (dataDf.empty == True):\n",
    "        continue \n",
    "        \n",
    "        \n",
    "    ####################################################################################################\n",
    "    \n",
    "    try:\n",
    "        writeDfToDb(dataDf, tableName, upsertKey, truncateBool, resumeFromRow, taskId)\n",
    "        print(\"DEBUG: Time for execution --- %s seconds ---\" % (time.time() - start_time))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"ERROR: Something went wrong in non database operations while writing for task id \" + taskId)\n",
    "        print(\"ERROR: \" + str(type(e).__name__))\n",
    "        print(\"ERROR: \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = getTableAsDf(oracleDbConnection, \"EXCEL_UPLOAD_MACH1_MASTER_TST4\")\n",
    "# print(temp.shape)\n",
    "# print(temp.columns)\n",
    "# query = \"\"\"\n",
    "# DELETE FROM EXCEL_UPLOAD_MACH1_MASTER_TST4 WHERE 'IPC Month' = '01/2018'\n",
    "# \"\"\"\n",
    "# runOracleQuery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "# SELECT  * FROM  DP_MACH1_FINAL_TABLE_NEW fetch first 3 rows only\n",
    "  \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "# PRODUCT : str, Product Code: str, GEOGRAPHY:str, CONCEPT:str, GRADE: str, TERMS:str, Price ID:int, UNIT: str, PRICE :int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = getTableAsDf(oracleDbConnection, \"DP_ZEMA_IHS_DAILY_BKUP\")\n",
    "# print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "# TRUNCATE TABLE EXCEL_UPLOAD_MACH1_MASTER_TST4  \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "# \n",
    "# query = \"\"\"CREATE TABLE \"EXCEL_UPLOAD_ICIS_INDEX_TEST\"     \n",
    "# ( \n",
    "# \"MONTH\" VARCHAR2(255), \n",
    "# \"Metric Name\" VARCHAR2(255), \n",
    "# \"PRODUCT\" VARCHAR2(255), \n",
    "# \"VALUE\" NUMBER(10,5), \n",
    "# \"REGION\" VARCHAR2(255), \n",
    "# \"CURR\" VARCHAR2(255), \n",
    "# \"UPLOAD_TIME\" VARCHAR2(255)    \n",
    "# )\"\"\"\n",
    "# runOracleQuery(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"\"\"\n",
    "# select * from EXCEL_UPLOAD_ICIS_INDEX_TEST  \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "# Create new table\n",
    "# query = \"\"\"\n",
    "# CREATE TABLE Excel_Upload_automation_JayFan \n",
    "# (col1 int,\n",
    "# col2 int,\n",
    "# col3 int,\n",
    "# col4 int,\n",
    "# col5 float,\n",
    "# col6 float,\n",
    "# col7 VARCHAR(26),\n",
    "# col8 VARCHAR(26),\n",
    "# col9 VARCHAR(26))\n",
    "# \"\"\"\n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT * FROM Excel_Upload_automation_JayFan\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# query = \"\"\"\n",
    "# CREATE TABLE Excel_Upload_automation_JF1 \n",
    "# (col1 varchar(26), pm varchar(26))\n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "# query = \"\"\"\n",
    "# TRUNCATE TABLE Excel_Upload_automation_JF1 \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "# query = \"\"\"\n",
    "# INSERT INTO Excel_Upload_automation_JF1 (col1)\n",
    "# VALUES (100)\n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "\n",
    "# print(getTableAsDf(oracleDbConnection, \"EXCEL_UPLOAD_MACH1_MASTER_TEST\"))\n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT table_name FROM all_tables\n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "\n",
    "# query = \"\"\"No Title\n",
    "# CREATE TABLE \"ACHEM_DRM\".\"EXCEL_UPLOAD_MACH1_MASTER_TEST\"     \n",
    "# ( \n",
    "# \t\t\t\"BU\" VARCHAR2(50), \n",
    "# \t\t  \"IPC Month\" VARCHAR2(100), \n",
    "# \t\t  \"Shipto ID\" VARCHAR2(100), \n",
    "# \t\t  \"Plant ID\" VARCHAR2(50), \n",
    "# \t\t  \"Material ID\" VARCHAR2(100), \n",
    "# \t\t  \"INCOTERMS\" VARCHAR2(100), \n",
    "# \t\t  \"Ship Condition ID\" VARCHAR2(100), \n",
    "# \t\t  \"Mode of Trans\" VARCHAR2(100), \n",
    "# \t\t  \"Sales type\" VARCHAR2(100), \n",
    "# \t\t  \"Sales Order Type\" VARCHAR2(100), \n",
    "# \t\t  \"End use ID\" VARCHAR2(100), \n",
    "# \t\t  \"VOLUME\" NUMBER(15,5), \n",
    "# \t\t  \"GR\" NUMBER(15,5), \n",
    "# \t\t  \"Cash Disc\" NUMBER(15,5), \n",
    "# \t\t  \"SURCHARGES\" NUMBER(15,5), \n",
    "# \t\t  \"Freight Revenue\" NUMBER(15,5), \n",
    "# \t\t  \"EPD\" NUMBER(15,5), \n",
    "# \t\t  \"NR\" NUMBER(15,5), \n",
    "# \t\t  \"Vol Rebt\" NUMBER(15,5), \n",
    "# \t\t  \"NNR\" NUMBER(15,5), \n",
    "# \t\t  \"NRM\" NUMBER(15,5), \n",
    "# \t\t  \"Import Duties\" NUMBER(15,5), \n",
    "# \t\t  \"Fees Oth Than Duty\" NUMBER(15,5), \n",
    "# \t\t  \"Duties Fees and Insur\" NUMBER(15,5), \n",
    "# \t\t  \"NRM & Packaging\" NUMBER(15,5), \n",
    "# \t\t  \"COGS\" NUMBER(15,5), \n",
    "# \t\t  \"Freight (STO)\" NUMBER(15,5), \n",
    "# \t\t  \"Inbound Expenses\" NUMBER(15,5), \n",
    "# \t\t  \"Gross Margin\" NUMBER(15,5), \n",
    "# \t\t  \"Chems & Cats\" NUMBER(15,5), \n",
    "# \t\t  \"Fuels & Util\" NUMBER(15,5), \n",
    "# \t\t  \"Other Variable Selling\" NUMBER(15,5), \n",
    "# \t\t  \"Freight - CGL8\" NUMBER(15,5), \n",
    "# \t\t  \"Freight - CGL7\" NUMBER(15,5), \n",
    "# \t\t  \"VSC\" NUMBER(15,5), \n",
    "# \t\t  \"Variable Distri\" NUMBER(15,5), \n",
    "# \t\t  \"VM\" NUMBER(15,5), \n",
    "# \t\t  \"Cust/Sales Area\" VARCHAR2(100), \n",
    "# \t\t  \"Sales Organization\" VARCHAR2(50), \n",
    "# \t\t  \"Mfg Plant ID\" VARCHAR2(50), \n",
    "# \t\t  \"UPLOAD_TIME\" DATE    ) \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "# query = \"\"\"CREATE TABLE \"EXCEL_UPLOAD_ICIS_INDEX_TEST\"     \n",
    "# ( \n",
    "# \t\t\t\"MONTH\" VARCHAR2(255), \n",
    "# \t\t  \"Metric Name\" VARCHAR2(255), \n",
    "# \t\t  \"PRODUCT\" VARCHAR2(255), \n",
    "# \t\t  \"REGION\" VARCHAR2(255), \n",
    "# \t\t  \"VALUE\" NUMBER(10,5), \n",
    "# \t\t  \"CURR\" VARCHAR2(255), \n",
    "# \t\t  \"UPLOAD_TIME\" VARCHAR2(255)    )\"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "# query = \"\"\"\n",
    "# drop table EXCEL_UPLOAD_ICIS_INDEX_TEST  \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "# query = \"\"\"CREATE TABLE \"EXCEL_UPLOAD_MACH1_SHIPTO_TST3\"     \n",
    "# ( \n",
    "# \t\t\t\"Cust/Sales Area\" VARCHAR2(50), \n",
    "# \t\t  \"Sales Organization\" VARCHAR2(50), \n",
    "# \t\t  \"BU\" VARCHAR2(50), \n",
    "# \t\t  \"Shipto ID\" VARCHAR2(50), \n",
    "# \t\t  \"Soldto ID\" VARCHAR2(50), \n",
    "# \t\t  \"Soldto Name\" VARCHAR2(65), \n",
    "# \t\t  \"Parent ID\" VARCHAR2(50), \n",
    "# \t\t  \"Parent Name\" VARCHAR2(50), \n",
    "# \t\t  \"Sales Manager ID\" VARCHAR2(50), \n",
    "# \t\t  \"Sales Manager\" VARCHAR2(50), \n",
    "# \t\t  \"Sales Person ID\" VARCHAR2(50), \n",
    "# \t\t  \"Sales Person Name\" VARCHAR2(61), \n",
    "# \t\t  \"Cust.Serv.Cl.of Sold to\" VARCHAR2(50), \n",
    "# \t\t  \"Cust.Serv.Cl.ShipTo\" VARCHAR2(50), \n",
    "# \t\t  \"Cust Class Name\" VARCHAR2(50), \n",
    "# \t\t  \"Alt Cust Grp3\" VARCHAR2(50), \n",
    "# \t\t  \"Alt Cust Grp2\" VARCHAR2(65), \n",
    "# \t\t  \"Alt Cust Grp1\" VARCHAR2(50), \n",
    "# \t\t  \"AREA\" VARCHAR2(50), \n",
    "# \t\t  \"Area Name\" VARCHAR2(50), \n",
    "# \t\t  \"REGION\" VARCHAR2(50), \n",
    "# \t\t  \"Region Name\" VARCHAR2(50), \n",
    "# \t\t  \"SUPERREGION\" VARCHAR2(50), \n",
    "# \t\t  \"SuperRegion Name\" VARCHAR2(50), \n",
    "# \t\t  \"Ship to Country ID\" VARCHAR2(50), \n",
    "# \t\t  \"Ship to Country Name\" VARCHAR2(50), \n",
    "# \t\t  \"VOLUME\" VARCHAR2(50), \n",
    "# \t\t  \"LOCATION\" VARCHAR2(50), \n",
    "# \t\t  \"Country Sub Div\" VARCHAR2(50), \n",
    "# \t\t  \"Country Sub Div Code\" VARCHAR2(10), \n",
    "# \t\t  \"UPLOAD_TIME\" VARCHAR2(30)    ) \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n",
    "\n",
    "# query = \"\"\"\n",
    "# CREATE TABLE  \"EXCEL_UPLOAD_MACH1_MASTER_TST4\"     \n",
    "# ( \n",
    "# \t\t\t\"BU\" VARCHAR2(50), \n",
    "# \t\t  \"IPC Month\" VARCHAR2(100), \n",
    "# \t\t  \"Shipto ID\" VARCHAR2(100), \n",
    "# \t\t  \"Plant ID\" VARCHAR2(50), \n",
    "# \t\t  \"Material ID\" VARCHAR2(100), \n",
    "# \t\t  \"INCOTERMS\" VARCHAR2(100), \n",
    "# \t\t  \"Ship Condition ID\" VARCHAR2(100), \n",
    "# \t\t  \"Mode of Trans\" VARCHAR2(100), \n",
    "# \t\t  \"Sales type\" VARCHAR2(100), \n",
    "# \t\t  \"Sales Order Type\" VARCHAR2(100), \n",
    "# \t\t  \"End use ID\" VARCHAR2(100), \n",
    "# \t\t  \"VOLUME\" NUMBER(15,5), \n",
    "# \t\t  \"GR\" NUMBER(15,5), \n",
    "# \t\t  \"Cash Disc\" NUMBER(15,5), \n",
    "# \t\t  \"SURCHARGES\" NUMBER(15,5), \n",
    "# \t\t  \"Freight Revenue\" NUMBER(15,5), \n",
    "# \t\t  \"EPD\" NUMBER(15,5), \n",
    "# \t\t  \"NR\" NUMBER(15,5), \n",
    "# \t\t  \"Vol Rebt\" NUMBER(15,5), \n",
    "# \t\t  \"NNR\" NUMBER(15,5), \n",
    "# \t\t  \"NRM\" NUMBER(15,5), \n",
    "# \t\t  \"Import Duties\" NUMBER(15,5), \n",
    "# \t\t  \"Fees Oth Than Duty\" NUMBER(15,5), \n",
    "# \t\t  \"Duties Fees and Insur\" NUMBER(15,5), \n",
    "# \t\t  \"NRM & Packaging\" NUMBER(15,5), \n",
    "# \t\t  \"COGS\" NUMBER(15,5), \n",
    "# \t\t  \"Freight (STO)\" NUMBER(15,5), \n",
    "# \t\t  \"Inbound Expenses\" NUMBER(15,5), \n",
    "# \t\t  \"Gross Margin\" NUMBER(15,5), \n",
    "# \t\t  \"Chems & Cats\" NUMBER(15,5), \n",
    "# \t\t  \"Fuels & Util\" NUMBER(15,5), \n",
    "# \t\t  \"Other Variable Selling\" NUMBER(15,5), \n",
    "# \t\t  \"Freight - CGL8\" NUMBER(15,5), \n",
    "# \t\t  \"Freight - CGL7\" NUMBER(15,5), \n",
    "# \t\t  \"VSC\" NUMBER(15,5), \n",
    "# \t\t  \"Variable Distri\" NUMBER(15,5), \n",
    "# \t\t  \"VM\" NUMBER(15,5), \n",
    "# \t\t  \"Cust/Sales Area\" VARCHAR2(100), \n",
    "# \t\t  \"Sales Organization\" VARCHAR2(50), \n",
    "# \t\t  \"Mfg Plant ID\" VARCHAR2(50), \n",
    "# \t\t  \"UPLOAD_TIME\" DATE    ) \n",
    "# \"\"\"\n",
    "# runOracleQuery(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "anaconda-project-anaconda50_py36-python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
